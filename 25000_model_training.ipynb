{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import faiss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import re\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.utils import resample\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from scipy.stats import uniform, randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Datasets/features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Label', 'Preprocessed_Content', 'sentiment', 'hate_speech_count',\n",
       "       'pos_tags', 'word2vec', 'sbert_embedding', 'lexical_diversity',\n",
       "       'sentence_complexity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    24973\n",
       "1    15027\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "0    15000\n",
      "1    15000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "class_0 = data[data['Label'] == 0]\n",
    "class_1 = data[data['Label'] == 1]\n",
    "\n",
    "class_0_sampled = resample(class_0, n_samples=25000, random_state=42)\n",
    "class_1_sampled = resample(class_1, n_samples=25000, random_state=42)\n",
    "\n",
    "balanced_data = pd.concat([class_0_sampled, class_1_sampled])\n",
    "\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(balanced_data['Label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings Shape: (30000, 384)\n"
     ]
    }
   ],
   "source": [
    "def convert_embedding(embedding):\n",
    "    if isinstance(embedding, np.ndarray):\n",
    "        return embedding\n",
    "    elif isinstance(embedding, list):\n",
    "        return np.array(embedding, dtype=np.float32)\n",
    "    elif isinstance(embedding, str):\n",
    "        embedding = embedding.strip(\"[]\")\n",
    "        embedding = np.array([float(x) for x in embedding.split()], dtype=np.float32)\n",
    "        return embedding\n",
    "    else:\n",
    "        return np.zeros(768, dtype=np.float32)\n",
    "\n",
    "train_data['sbert_embedding'] = train_data['sbert_embedding'].apply(convert_embedding)\n",
    "\n",
    "embeddings = np.stack(train_data['sbert_embedding'].values)\n",
    "\n",
    "print(\"Embeddings Shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "faiss_index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(2, 3), stop_words='english')\n",
    "X_tfidf = tfidf.fit_transform(train_data['Preprocessed_Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2, 3), stop_words='english')\n",
    "X_bow = vectorizer.fit_transform(train_data['Preprocessed_Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack([\n",
    "    X_tfidf,\n",
    "    X_bow,  \n",
    "    embeddings,\n",
    "    train_data[['sentiment', 'hate_speech_count', 'lexical_diversity', 'sentence_complexity']].values\n",
    "])\n",
    "\n",
    "Y = train_data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "numerical_features = train_data[['sentiment', 'hate_speech_count', 'lexical_diversity', 'sentence_complexity']].values\n",
    "numerical_features_scaled = scaler.fit_transform(numerical_features)\n",
    "\n",
    "scaled_sparse = csr_matrix(numerical_features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_res, Y_res = smote.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_res, Y_res, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.unique(Y_res), y=Y_res)\n",
    "class_weight_dict = dict(zip(np.unique(Y_res), class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Trained\n",
      "Logistic Regression Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      3043\n",
      "           1       0.85      0.85      0.85      2957\n",
      "\n",
      "    accuracy                           0.85      6000\n",
      "   macro avg       0.85      0.85      0.85      6000\n",
      "weighted avg       0.85      0.85      0.85      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === LOGISTIC REGRESSION ===\n",
    "logistic_model = LogisticRegression(max_iter=500, C=1.0)\n",
    "logistic_model.fit(X_train, Y_train)\n",
    "print('Logistic Regression Trained')\n",
    "\n",
    "logistic_pred = logistic_model.predict(X_test)\n",
    "print(\"Logistic Regression Performance:\")\n",
    "print(classification_report(Y_test, logistic_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Trained\n",
      "SVM Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85      3043\n",
      "           1       0.87      0.80      0.84      2957\n",
      "\n",
      "    accuracy                           0.85      6000\n",
      "   macro avg       0.85      0.85      0.85      6000\n",
      "weighted avg       0.85      0.85      0.85      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === SVM using RandomizedSearchCV ===\n",
    "svm_params = {'C': np.logspace(-2, 2, 5), 'kernel': ['rbf']}\n",
    "svm_model = RandomizedSearchCV(SVC(cache_size=1000), svm_params, n_iter=3, cv=2, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "svm_model.fit(X_train, Y_train)\n",
    "print('SVM Trained')\n",
    "\n",
    "svm_pred = svm_model.best_estimator_.predict(X_test)\n",
    "print(\"SVM Performance:\")\n",
    "print(classification_report(Y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "Random Forest Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86      3043\n",
      "           1       0.88      0.83      0.85      2957\n",
      "\n",
      "    accuracy                           0.86      6000\n",
      "   macro avg       0.86      0.86      0.86      6000\n",
      "weighted avg       0.86      0.86      0.86      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === RFC using RandomizedSearchCV ===\n",
    "rf_params = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf_model = RandomizedSearchCV(\n",
    "    RandomForestClassifier(n_jobs=-1, random_state=42), \n",
    "    rf_params, \n",
    "    n_iter=3, \n",
    "    cv=2, \n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1, \n",
    "    verbose=1, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, Y_train)\n",
    "\n",
    "rf_pred = rf_model.best_estimator_.predict(X_test)\n",
    "print(\"Random Forest Performance:\")\n",
    "print(classification_report(Y_test, rf_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
