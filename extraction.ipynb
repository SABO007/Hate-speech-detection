{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-18 14:54:48.279764: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from textblob import TextBlob\n",
    "import gensim.downloader as api\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qq/g1fc9b_10d1gd8z3wl4n208w0000gn/T/ipykernel_28648/1752640760.py:1: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"Datasets/preprocessed.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "      <th>Content_int</th>\n",
       "      <th>Cleaned_Content</th>\n",
       "      <th>Preprocessed_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>denial of normal the con be asked to comment o...</td>\n",
       "      <td>1</td>\n",
       "      <td>[146715, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,...</td>\n",
       "      <td>denial of normal the con be asked to comment o...</td>\n",
       "      <td>denial normal con ask comment tragedy emotiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>just by being able to tweet this insufferable ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[146715, 14, 15, 16, 17, 7, 18, 19, 20, 21, 22...</td>\n",
       "      <td>just by being able to tweet this insufferable ...</td>\n",
       "      <td>able tweet insufferable bullshit proves trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that is retarded you too cute to be single tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>[146715, 28, 29, 30, 26, 31, 32, 7, 5, 33, 28,...</td>\n",
       "      <td>that is retarded you too cute to be single tha...</td>\n",
       "      <td>retard cute single life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thought of a real badass mongol style declarat...</td>\n",
       "      <td>1</td>\n",
       "      <td>[146715, 35, 1, 24, 36, 37, 38, 39, 40, 1, 41,...</td>\n",
       "      <td>thought of a real badass mongol style declarat...</td>\n",
       "      <td>thought real badass mongol style declaration w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afro american basho</td>\n",
       "      <td>1</td>\n",
       "      <td>[146715, 46, 47, 48, 146714]</td>\n",
       "      <td>afro american basho</td>\n",
       "      <td>afro american basho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440901</th>\n",
       "      <td>crash another movie from left field i have to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[146715, 1780, 649, 1673, 347, 701, 1702, 80, ...</td>\n",
       "      <td>crash another movie from left field i have to ...</td>\n",
       "      <td>crash movie left field ask star war episode ii...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440902</th>\n",
       "      <td>i why do not you debate first before starting ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[146715, 80, 186, 340, 76, 26, 6407, 566, 2608...</td>\n",
       "      <td>i why do not you debate first before starting ...</td>\n",
       "      <td>debate start edit war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440903</th>\n",
       "      <td>removal of i reverted the removal of the above...</td>\n",
       "      <td>0</td>\n",
       "      <td>[146715, 18731, 1, 80, 48182, 3, 18731, 1, 3, ...</td>\n",
       "      <td>removal of i reverted the removal of the above...</td>\n",
       "      <td>removal revert removal section believe misguid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440904</th>\n",
       "      <td>i have unblocked you eddie as i discussed on u...</td>\n",
       "      <td>0</td>\n",
       "      <td>[146715, 80, 87, 20515, 26, 10684, 273, 80, 95...</td>\n",
       "      <td>i have unblocked you eddie as i discussed on u...</td>\n",
       "      <td>unblock eddie discuss user talkable accuse nil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440905</th>\n",
       "      <td>you have the ability to delete that revision a...</td>\n",
       "      <td>0</td>\n",
       "      <td>[146715, 26, 87, 3, 12795, 7, 3358, 28, 3938, ...</td>\n",
       "      <td>you have the ability to delete that revision a...</td>\n",
       "      <td>ability delete revision survivor exile island ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>440906 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Content Label  \\\n",
       "0       denial of normal the con be asked to comment o...     1   \n",
       "1       just by being able to tweet this insufferable ...     1   \n",
       "2       that is retarded you too cute to be single tha...     1   \n",
       "3       thought of a real badass mongol style declarat...     1   \n",
       "4                                     afro american basho     1   \n",
       "...                                                   ...   ...   \n",
       "440901  crash another movie from left field i have to ...     0   \n",
       "440902  i why do not you debate first before starting ...     0   \n",
       "440903  removal of i reverted the removal of the above...     0   \n",
       "440904  i have unblocked you eddie as i discussed on u...     0   \n",
       "440905  you have the ability to delete that revision a...     0   \n",
       "\n",
       "                                              Content_int  \\\n",
       "0       [146715, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,...   \n",
       "1       [146715, 14, 15, 16, 17, 7, 18, 19, 20, 21, 22...   \n",
       "2       [146715, 28, 29, 30, 26, 31, 32, 7, 5, 33, 28,...   \n",
       "3       [146715, 35, 1, 24, 36, 37, 38, 39, 40, 1, 41,...   \n",
       "4                            [146715, 46, 47, 48, 146714]   \n",
       "...                                                   ...   \n",
       "440901  [146715, 1780, 649, 1673, 347, 701, 1702, 80, ...   \n",
       "440902  [146715, 80, 186, 340, 76, 26, 6407, 566, 2608...   \n",
       "440903  [146715, 18731, 1, 80, 48182, 3, 18731, 1, 3, ...   \n",
       "440904  [146715, 80, 87, 20515, 26, 10684, 273, 80, 95...   \n",
       "440905  [146715, 26, 87, 3, 12795, 7, 3358, 28, 3938, ...   \n",
       "\n",
       "                                          Cleaned_Content  \\\n",
       "0       denial of normal the con be asked to comment o...   \n",
       "1       just by being able to tweet this insufferable ...   \n",
       "2       that is retarded you too cute to be single tha...   \n",
       "3       thought of a real badass mongol style declarat...   \n",
       "4                                     afro american basho   \n",
       "...                                                   ...   \n",
       "440901  crash another movie from left field i have to ...   \n",
       "440902  i why do not you debate first before starting ...   \n",
       "440903  removal of i reverted the removal of the above...   \n",
       "440904  i have unblocked you eddie as i discussed on u...   \n",
       "440905  you have the ability to delete that revision a...   \n",
       "\n",
       "                                     Preprocessed_Content  \n",
       "0       denial normal con ask comment tragedy emotiona...  \n",
       "1       able tweet insufferable bullshit proves trump ...  \n",
       "2                                 retard cute single life  \n",
       "3       thought real badass mongol style declaration w...  \n",
       "4                                     afro american basho  \n",
       "...                                                   ...  \n",
       "440901  crash movie left field ask star war episode ii...  \n",
       "440902                              debate start edit war  \n",
       "440903  removal revert removal section believe misguid...  \n",
       "440904  unblock eddie discuss user talkable accuse nil...  \n",
       "440905  ability delete revision survivor exile island ...  \n",
       "\n",
       "[440906 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Datasets/preprocessed.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data = data.reset_index()\n",
    "data = data.drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440222"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Label\"] = data[\"Label\"].astype(str)\n",
    "\n",
    "data[\"Label\"] = data[\"Label\"].apply(lambda x: 1 if x == '1' else 0 if x == '0' else x)\n",
    "\n",
    "data = data[data[\"Label\"].isin([0, 1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440215"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "      <th>Content_int</th>\n",
       "      <th>Cleaned_Content</th>\n",
       "      <th>Preprocessed_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>denial of normal the con be asked to comment o...</td>\n",
       "      <td>1</td>\n",
       "      <td>[146715, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,...</td>\n",
       "      <td>denial of normal the con be asked to comment o...</td>\n",
       "      <td>denial normal con ask comment tragedy emotiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>just by being able to tweet this insufferable ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[146715, 14, 15, 16, 17, 7, 18, 19, 20, 21, 22...</td>\n",
       "      <td>just by being able to tweet this insufferable ...</td>\n",
       "      <td>able tweet insufferable bullshit proves trump ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that is retarded you too cute to be single tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>[146715, 28, 29, 30, 26, 31, 32, 7, 5, 33, 28,...</td>\n",
       "      <td>that is retarded you too cute to be single tha...</td>\n",
       "      <td>retard cute single life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thought of a real badass mongol style declarat...</td>\n",
       "      <td>1</td>\n",
       "      <td>[146715, 35, 1, 24, 36, 37, 38, 39, 40, 1, 41,...</td>\n",
       "      <td>thought of a real badass mongol style declarat...</td>\n",
       "      <td>thought real badass mongol style declaration w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afro american basho</td>\n",
       "      <td>1</td>\n",
       "      <td>[146715, 46, 47, 48, 146714]</td>\n",
       "      <td>afro american basho</td>\n",
       "      <td>afro american basho</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content Label  \\\n",
       "0  denial of normal the con be asked to comment o...     1   \n",
       "1  just by being able to tweet this insufferable ...     1   \n",
       "2  that is retarded you too cute to be single tha...     1   \n",
       "3  thought of a real badass mongol style declarat...     1   \n",
       "4                                afro american basho     1   \n",
       "\n",
       "                                         Content_int  \\\n",
       "0  [146715, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,...   \n",
       "1  [146715, 14, 15, 16, 17, 7, 18, 19, 20, 21, 22...   \n",
       "2  [146715, 28, 29, 30, 26, 31, 32, 7, 5, 33, 28,...   \n",
       "3  [146715, 35, 1, 24, 36, 37, 38, 39, 40, 1, 41,...   \n",
       "4                       [146715, 46, 47, 48, 146714]   \n",
       "\n",
       "                                     Cleaned_Content  \\\n",
       "0  denial of normal the con be asked to comment o...   \n",
       "1  just by being able to tweet this insufferable ...   \n",
       "2  that is retarded you too cute to be single tha...   \n",
       "3  thought of a real badass mongol style declarat...   \n",
       "4                                afro american basho   \n",
       "\n",
       "                                Preprocessed_Content  \n",
       "0  denial normal con ask comment tragedy emotiona...  \n",
       "1  able tweet insufferable bullshit proves trump ...  \n",
       "2                            retard cute single life  \n",
       "3  thought real badass mongol style declaration w...  \n",
       "4                                afro american basho  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_speech_words = [\n",
    "    'hate', 'violence', 'abuse', 'offend', 'discrimination', 'racism', 'oppression', 'bigot', 'ignorant', \n",
    "    'supremacist', 'feminazi', 'cunt', 'slut', 'whore', 'bitch', 'skank', 'thot', 'ho', 'gold digger', \n",
    "    'motherfucker', 'cockroach', 'asshole', 'dickhead', 'prick', 'scumbag', 'bastard', 'fuck', 'nigga', \n",
    "    'nigger', 'chink', 'gook', 'spic', 'wetback', 'cracker', 'honky', 'kike', 'wog', 'towelhead', \n",
    "    'sandnigger', 'faggot', 'fag', 'dyke', 'tranny', 'homo', 'sissy', 'fairy', 'pansy', 'sodomite', \n",
    "    'infidel', 'heathen', 'crusader', 'raghead', 'jihadist', 'taliban', 'beaner', 'gypsy', 'paki', \n",
    "    'wop', 'dago', 'mick', 'jap', 'yid', 'kaffir', 'cholo', 'zebra', 'white trash', 'redneck', 'hillbilly',\n",
    "    'karen', 'snowflake', 'beta', 'incel', 'simp', 'boomer', 'npc', 'soyboy', 'mgtow', 'swine', 'trumpist', \n",
    "    'libtard', 'nazi', 'commie', 'sjw', 'ratchet', 'ghetto', 'redpill', 'based', 'chad', 'beta male', \n",
    "    'alpha male', 'cuck', 'cock', 'broke bitch', 'pussy ass', 'turd', 'feminist', 'terrorist', 'islamist'\n",
    "]\n",
    "\n",
    "word2vec_model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "def detect_hate_speech(text):\n",
    "    return sum([1 for word in hate_speech_words if word in text.lower()])\n",
    "\n",
    "def pos_tagging(text):\n",
    "    doc = nlp(text)\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "    return pos_tags\n",
    "\n",
    "def get_word2vec_embedding(text):\n",
    "    tokens = [token.text.lower() for token in nlp(text)]\n",
    "    word_vectors = [word2vec_model[word] for word in tokens if word in word2vec_model]\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "def lexical_diversity(text):\n",
    "    tokens = [token.text for token in nlp(text)]\n",
    "    return len(set(tokens)) / len(tokens) if len(tokens) > 0 else 0\n",
    "\n",
    "def sentence_complexity(text):\n",
    "    return len(re.findall(r'\\.', text))\n",
    "\n",
    "def get_sbert_embedding(text):\n",
    "    return sbert_model.encode(text, convert_to_numpy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis done\n",
      "Hate speech detection done\n",
      "POS tagging detection done\n",
      "Word2Vec embedding done\n",
      "SBERT embedding done\n",
      "Lexical diversity done\n",
      "Sentence complexity done\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "data['sentiment'] = data['Preprocessed_Content'].apply(sentiment_analysis)\n",
    "print('Sentiment analysis done')\n",
    "\n",
    "data['hate_speech_count'] = data['Preprocessed_Content'].apply(detect_hate_speech)\n",
    "print('Hate speech detection done')\n",
    "\n",
    "data['pos_tags'] = data['Preprocessed_Content'].apply(pos_tagging)\n",
    "print('POS tagging detection done')\n",
    "\n",
    "data['word2vec'] = data['Preprocessed_Content'].apply(get_word2vec_embedding)\n",
    "print('Word2Vec embedding done')\n",
    "\n",
    "data['sbert_embedding'] = data['Preprocessed_Content'].apply(get_sbert_embedding)\n",
    "print('SBERT embedding done')\n",
    "\n",
    "data['lexical_diversity'] = data['Preprocessed_Content'].apply(lexical_diversity)\n",
    "print('Lexical diversity done')\n",
    "\n",
    "data['sentence_complexity'] = data['Preprocessed_Content'].apply(sentence_complexity)\n",
    "print('Sentence complexity done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset=['Preprocessed_Content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Content', 'Content_int', 'Cleaned_Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Label', 'Preprocessed_Content', 'sentiment', 'hate_speech_count',\n",
       "       'pos_tags', 'word2vec', 'sbert_embedding', 'lexical_diversity',\n",
       "       'sentence_complexity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407364"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the dataset with extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"Datasets/features.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
