{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from textblob import TextBlob\n",
    "import gensim.downloader as api\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Content  Label  \\\n",
      "0                                                 Content  Label   \n",
      "1       denial of normal the con be asked to comment o...      1   \n",
      "2       just by being able to tweet this insufferable ...      1   \n",
      "3       that is retarded you too cute to be single tha...      1   \n",
      "4       thought of a real badass mongol style declarat...      1   \n",
      "...                                                   ...    ...   \n",
      "440902  crash another movie from left field i have to ...      0   \n",
      "440903  i why do not you debate first before starting ...      0   \n",
      "440904  removal of i reverted the removal of the above...      0   \n",
      "440905  i have unblocked you eddie as i discussed on u...      0   \n",
      "440906  you have the ability to delete that revision a...      0   \n",
      "\n",
      "                                              Content_int  \n",
      "0                                             Content_int  \n",
      "1       [146715, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,...  \n",
      "2       [146715, 14, 15, 16, 17, 7, 18, 19, 20, 21, 22...  \n",
      "3       [146715, 28, 29, 30, 26, 31, 32, 7, 5, 33, 28,...  \n",
      "4       [146715, 35, 1, 24, 36, 37, 38, 39, 40, 1, 41,...  \n",
      "...                                                   ...  \n",
      "440902  [146715, 1780, 649, 1673, 347, 701, 1702, 80, ...  \n",
      "440903  [146715, 80, 186, 340, 76, 26, 6407, 566, 2608...  \n",
      "440904  [146715, 18731, 1, 80, 48182, 3, 18731, 1, 3, ...  \n",
      "440905  [146715, 80, 87, 20515, 26, 10684, 273, 80, 95...  \n",
      "440906  [146715, 26, 87, 3, 12795, 7, 3358, 28, 3938, ...  \n",
      "\n",
      "[440907 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Datasets/Final_data_Y_D.csv\", names=[\"Content\", \"Label\", \"Content_int\"], header=None)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440907"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "0        361594\n",
      "1         79305\n",
      "Label         8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to clean text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isnull(text) or not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text) \n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip().lower() \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization, lemmatization, and stopword removal using spaCy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    doc = nlp(text)  \n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha] \n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cleaned_Content'] = data['Content'].apply(clean_text)\n",
    "\n",
    "data['Content'] = data['Cleaned_Content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"Datasets/preprocessed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
